---
slug: google-data-analytics
title: Food Import Cost Case Study
date: 2023-11-12
lastmod: ["lastmod", ":git", "date", "publishDate"]
tags: ["R", "ggplot", "python", "statistics", "matplotlib"]
---

This topic was chosen as there is a lot that goes into the production of food. A level of concern was raised as it became obvious that people with various disorders are struggling to get the food items they can have. By this it is meant, those with Crohn's disease, restrictive diets due to genetics (dysautonomia, EDS, ANS, etc), as well as many others. Medications can make the lack of proper foods tolerable, but it does not solve the overall issue they have.
<!--more-->

# Week 1

## Setup
```{r setup, include=FALSE}
library(knitr)
knitr::opts_knit$set(root.dir = ".")
```
The libraries in use:
```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(plotly)
library(readxl)
```
## Planning Stage

1)  Find the data set(s) for food production costs (first place to look is USDA)\
2)  Find the data set(s) for consumer cost of the items (USDA?)\
3)  Start plotting the costs against each other (Smooth vs Bar charts)\
4)  Figure out the pattern in the data (likely going to have go back over the course of a few years (on returning, apparently decades))

The main question, why does food cost so much? To answer this question, we need a few bits of data to start with. Those data sets are, the current cost to produce (e.g. grow fruits) and/or manufacture (e.g. process grains) the food items. From there, we need to get a data set for the cost to consumers of these same items. Considering that I live in the United States, I'll be working with those data sets first.

## Let's begin

Time to start gathering the data sets. Charts will appear in the order made in the order of the data sets. If more data sets are listed than there are charts, then the initial exploration of the data is not done.

Well, we have two charts made showing the breakdown of imported goods and the year-over-year change in cost. The spikes in import price or the amount of food still needed to be imported raises some concern. Further review will be needed to provide, not only context, but an explanation as to why we saw such a sharp increase.

# End of Week 1 Update

The data is immense. As of right now, the data still requires some restructuring for it to be more accessible for visualization. The Vegetables and Pulses Yearbook, while extensive (50+ tables), is structured for spreadsheet use. Have a happy holiday!

# Week 2

The line chart is the average of imported vegetables and pulses available by US pounds per person. It was made using ggplot2 and a custom data frame.

# End of Week 2

Upon further review, there are a lot of missing pieces. Namely, trade agreements. While we have import costs, this would be offset by trades with respective countries. For example, exporting wheat to import avocados. 

# Data sets

[Food Imports](https://www.ers.usda.gov/data-products/u-s-food-imports/)\
[Vegetables and Pulses Yearbook](https://www.ers.usda.gov/data-products/vegetables-and-pulses-data/vegetables-and-pulses-yearbook-tables/)\
[Farm Output](https://www.ers.usda.gov/data-products/agricultural-productivity-in-the-u-s/)\
[Dairy](https://www.ers.usda.gov/data-products/dairy-data.aspx)

# Charts

![2022 US Imports (Spreadsheet)](img/2022-US-Imports.png)  
This is the breakdown of all the imported food and preparatory items, by category.

![US Imported Food YoY (Spreadsheet)](img/US-Imported-Food-Price-Change.png)  
This chart is rather misleading when first looking at it. While the data used to prepare this chart is accurate, it does not take into account trade agreements. There is a possibility that that the true change is much flatter. The data does not make a distinction towards either true expense or expense minus trades.

Now, for some R plots. Sheet 3 is "U.S. per capita availability of selected, commercially produced, fresh and processing vegetables and dry pulse crops".
```{r echo=TRUE, out.height=400, out.width=500, message=FALSE, warning=FALSE}
pc <- read_xlsx("datasets/VPPT.xlsx", sheet = 3)

avg <- setNames(aggregate(pc$Value, list(pc$Year), FUN= function(x) round(mean(x), 2)), c("year", "value"))

p <- ggplot(avg, aes(year, value)) +
  geom_line() +
  labs(title = "Average Vegetables and Pulses Per Person") +
  ylab("Weight per Person (lbs)") + xlab("Year")

ggplotly(p)
```
Keep in mind, this is for the <strong>WHOLE YEAR</strong>.

For a month-to-month basis, we would need to divide the value by 12.
```{r echo=TRUE, message=FALSE, warning=FALSE}
avg_monthly <- setNames(aggregate(pc$Value, list(pc$Year), FUN= function(x) round(mean(x)/12, 2)), c("year", "value"))

p2 <- ggplot(avg_monthly, aes(year, value)) +
  geom_line() +
  labs(title = "Average Vegetables and Pulses Per Person Per Month") +
  ylab("Weight per Person (lbs)") + xlab("Year")

ggplotly(p2)
```


Now for some python fun. Let's begin by loading R's python package.
```{r message=FALSE, warning=FALSE, results='hide'}
# if it is not already installed, run the following command
# install.packages('reticulate', repos="http://cran.us.r-project.org")
library(reticulate)
```
Load python's respective packages.
```{python}
# if they are not installed, run the following command
# pip install pandas matplotlib
import pandas as pd
import matplotlib.pyplot as plt
```
Now, we're going to load up a CSV containing the cost of vegetables.
```{python}
df = pd.read_csv('datasets/veggies-2020.csv')
df.info()
```
Now we have different forms of vegetables, retail price, and so much more. The key columns here are going to be the name, Form, RetailPrice, and Yield. Why yield? Well, depending on how you use them, you may lose a good amount of of what you purchased. Something not usually considered when buying vegetables.

## Additional Questions

1.  Why did 2008 and 2013 have the largest percentage change?
2.  In the line chart, we see a steep drop at 1980, what happened?
3.  In the line chart, we see a spike at 2020, what happened? 
