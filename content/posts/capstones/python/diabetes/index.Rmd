---
slug: scikit-learn
title: Diabetes XGBoost testing
date: 2023-12-11
lastmod: ["lastmod", ":git", "date", "publishDate"]
tags: ["python", "statistics", "scikit-learn", "xgboost"]
---

## Steps
1. Load the "diabetes.csv" dataset using Pandas &check;  
2. Split the data into 80% for training and 20% for testing &check; 
3. Train an XG-Boost classifier model using SK-Learn Library &check;  
4. Assess trained model performance  
5. Plot the confusion matrix  
6. Print the classification report

Before beginning, I am using RStudio so loading R's reticulate library is first.
```{r message=FALSE, warning=FALSE, error=FALSE}
library(reticulate)
```
Now, import all of the required Python libraries.
```{python message=FALSE, warning=FALSE, error=FALSE}
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
```
Import the dataset.
```{python message=FALSE, warning=FALSE, error=FALSE}
df = pd.read_csv('dataset/diabetes.csv')
df.info()
```
Histogram plots to check distribution.
```{python message=FALSE, warning=FALSE, error=FALSE, results='hide'}
df.hist(bins=30, figsize=(20,20), color='b')
```
Check Correlation.
```{python message=FALSE, warning=FALSE, error=FALSE}
correlation = df.corr()
f, ax = plt.subplots(figsize=(20,20))
sns.heatmap(correlation, annot=True)
```
Split the data into testing and training.
```{python message=FALSE, warning=FALSE, error=FALSE}
y=df['Outcome']
X=df.drop(['Outcome'], axis=1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(f'X Train: {X_train.shape}, X_test: {X_test.shape}, y_train: {y_train.shape}, y_test: {y_test.shape}')
```
Train XGBoost classifier.
```{python message=FALSE, warning=FALSE, error=FALSE}
xgb_classifier = XGBClassifier(objective='binary:logistic', eval_metric='error', learning_rate=0.1, max_depth=5, n_estimators=10, use_label_encoder=False)
xgb_classifier.fit(X_train, y_train)
```
Check results.
```{python message=FALSE, warning=FALSE, error=FALSE}
result = xgb_classifier.score(X_test, y_test)
print(f'Accuracy: {result}')

y_predict = xgb_classifier.predict(X_test)
```
Predictions on test data.
```{python message=FALSE, warning=FALSE, error=FALSE}
from sklearn.metrics import classification_report
print(classification_report(y_test, y_predict))
```